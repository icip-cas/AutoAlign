# SPIN: Self-Play Fine-Tuning

SPIN utilizes a self-play mechanism, allowing an LLM to improve itself by playing against its previous iterations, without needing additional human-annotated preference data than the SFT dataset itself. More specifically, the LLM generates its own training data from its previous iterations, refining its policy by discerning these self-generated responses from the original SFT data.

## ğŸ“‚ Data Preparation

## ğŸ›  Usage

## ğŸ“ˆ Reference Results

## ğŸ“œ Citation
