import streamlit as st
import os
import time
from pages.navigation import render_navbar, init_session_state
import subprocess

render_navbar()
hide_sidebar_css = """
<style>
    section[data-testid="stSidebar"] {
        display: none !important;
    }
</style>
"""
st.markdown(hide_sidebar_css, unsafe_allow_html=True)
st.title("ğŸ“Š Model Evaluation")

# åˆå§‹åŒ– session_state
if "process" not in st.session_state:
    st.session_state["process"] = "objective_all"
if "model_dir" not in st.session_state:
    st.session_state["model_dir"] = ""
if "output_dir" not in st.session_state:
    st.session_state["output_dir"] = ""
if "model_name" not in st.session_state:
    st.session_state["model_name"] = ""  # åˆå§‹åŒ–ä¸ºç©ºå­—ç¬¦ä¸²
if "per_model_gpu" not in st.session_state:
    st.session_state["per_model_gpu"] = 1
if "batch_size" not in st.session_state:
    st.session_state["batch_size"] = 8


process_descriptions = {
    "objective_core": "GSM-8K(EN)ï¼ŒMATH(EN)ï¼ŒHumanEval(EN)ï¼ŒHumanEval-CN(CH)ï¼ŒBBH(EN)ï¼ŒIFEval(EN)ï¼ŒCONFIG_ALLï¼š",
    "objective_all": "GSM-8K(EN)ï¼ŒMATH(EN)ï¼ŒHumanEval(EN)HumanEval-CN(CH)ï¼ŒBBH(EN)ï¼ŒIFEval(EN)ï¼ŒCMMLU(CH)ï¼ŒC-Eval(CH)ï¼ŒMBPP(EN)ï¼ŒMBPP-CN(CH)ï¼ŒGPQA(EN)",
    "subjective": "MT-Bench and Alpaca-Eval",
}

# ç¾åŒ–æ ‡é¢˜å’Œåˆ†éš”çº¿
st.markdown("---")
st.subheader("ğŸ“Š BenchMark")

# åœ¨è¡¨å•å¤–ä½¿ç”¨ st.selectboxï¼Œä»¥ä¾¿ä½¿ç”¨ on_change å›è°ƒ
process = st.selectbox(
    "é€‰æ‹©è¯„æµ‹ç±»å‹",
    options=[
        "objective_core",
        "objective_all",
        "subjective",
    ],
    index=[
        "objective_core",
        "objective_all",
        "subjective",
    ].index(st.session_state["process"]),  # æ¢å¤ process çš„é€‰æ‹©çŠ¶æ€
    key="process_selectbox",
    on_change=lambda: st.session_state.update(
        {"process": process}
    ),  # æ›´æ–° session_state
)

# æ ¹æ® session_state ä¸­çš„ process åŠ¨æ€æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
st.markdown(
    f"""
    <style>
    .info-box {{
        padding: 15px;
        background-color: #f0f2f6;
        border-radius: 10px;
        border-left: 5px solid #4a90e2;
        margin-top: 10px;
        margin-bottom: 20px;
    }}
    .info-box p {{
        margin: 0;
        font-size: 14px;
        color: #333;
    }}
    </style>
    <div class="info-box">
        <p>ğŸ“Œ <strong>Benchmark:</strong> {process_descriptions.get(st.session_state["process"], "æš‚æ— æè¿°")}</p>
    </div>
    """,
    unsafe_allow_html=True,
)

# é…ç½®è¡¨å•
with st.form("config_form"):
    st.markdown("---")
    st.subheader("ğŸ“‚ Model Selection")

    # æ¨¡å‹è·¯å¾„è¾“å…¥
    model_dir = st.text_input(
        "æ¨¡å‹è·¯å¾„",
        placeholder="è¯·è¾“å…¥æ¨¡å‹è·¯å¾„",
        value=st.session_state["model_dir"],  # æ¢å¤ model_dir çš„è¾“å…¥å†…å®¹
        label_visibility="collapsed",
    )

    # è¯„æµ‹çš„æ¨¡å‹æ ‡è¯†åç§°
    st.subheader("ğŸ·ï¸ Model Name")
    model_name = st.text_input(
        "æ¨¡å‹åç§°",
        placeholder="è¯·è¾“å…¥æ¨¡å‹æ ‡è¯†åç§°",
        # value=st.session_state["model_name"],  # ä½¿ç”¨ session_state ä¸­çš„å€¼
        value="aaa",
        label_visibility="collapsed",
    )

    #è¾“å‡ºåœ°å€
    st.subheader("ğŸ“„ Output Path")
    output_path = st.text_input(
        "é…ç½®æ–‡ä»¶å­˜å‚¨è·¯å¾„",
        placeholder="è¯·è¾“å…¥é…ç½®å­˜å‚¨è·¯å¾„",
        value = "ata-output",
        label_visibility="collapsed"
    )

    # GPU å’Œ Batch Size é…ç½®
    st.markdown("---")
    st.subheader("âš™ï¸ GPU and Batch Size Configuration")
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("**GPU per Model**")
        per_model_gpu = st.number_input(
            "æ¯ä¸ªæ¨¡å‹çš„ GPU æ•°é‡",
            min_value=1,
            value=st.session_state["per_model_gpu"],
            step=1,
            label_visibility="collapsed",
        )
    with col2:
        st.markdown("**Batch Size**")
        batch_size = st.number_input(
            "æ‰¹é‡å¤§å°",
            min_value=1,
            value=st.session_state["batch_size"],  # æ¢å¤ batch_size çš„è¾“å…¥å†…å®¹
            step=1,
            label_visibility="collapsed",
        )

    # æäº¤æŒ‰é’®
    st.markdown("---")
    submitted = st.form_submit_button("ğŸš€")

    # è¡¨å•æäº¤åçš„é€»è¾‘
    if submitted:
        # ä¿å­˜ç”¨æˆ·è¾“å…¥åˆ° session_state
        st.session_state["process"] = process
        st.session_state["model_dir"] = model_dir
        st.session_state["model_name"] = model_name
        st.session_state["per_model_gpu"] = per_model_gpu
        st.session_state["batch_size"] = batch_size
        st.session_state["output_dir"] = output_path

        all_fields_filled = True

        # æ£€æŸ¥ Model Dir æ˜¯å¦å­˜åœ¨
        if not model_dir:
            st.error("âŒ è¯·æä¾›æ¨¡å‹è·¯å¾„ã€‚")
            all_fields_filled = False
        elif not os.path.exists(model_dir):
            st.error(f"âŒ æ¨¡å‹è·¯å¾„ '{model_dir}' ä¸å­˜åœ¨ã€‚")
            all_fields_filled = False

        # æ£€æŸ¥ Model Name æ˜¯å¦ä¸ºç©º
        if not model_name:
            st.error("âŒ è¯·æä¾›æ¨¡å‹åç§°ã€‚")
            all_fields_filled = False

        # å¦‚æœæ‰€æœ‰å­—æ®µåˆæ³•ä¸”è·¯å¾„æ£€æŸ¥é€šè¿‡
        if all_fields_filled:
            # æ ¹æ®è¯„æµ‹ç±»å‹è®¾ç½® mt_path å’Œ alpaca_path
            mt_path = "data/eval/mt-bench"
            alpaca_path = "data/eval/alpaca_eval" if process == "subjective" else None

            # ç”Ÿæˆé…ç½®æ–‡ä»¶å†…å®¹
            config_content = f"""
model_name: {model_name}
template_name: chatml-keep-system
model_path: {model_dir}
eval_type: {process}
per_model_gpu: {per_model_gpu}
batch_size: {batch_size}
backend: vllm
opencompass_path: opencompass
mt_path: {mt_path}
judge_model: chatgpt_fn
"""

            if alpaca_path:
                config_content += f"""
alpaca_path: {alpaca_path}
"""
            st.session_state.step4 = config_content
            st.session_state.p4_fin = True
            st.success(f"Align Start!")
            time.sleep(1.5)
            #  TODO: åœ¨è¿™é‡Œæ’å…¥æ‰§è¡Œä¸€æ¬¡æ€§è„šæœ¬çš„å†…å®¹
            os.environ['step1'] = st.session_state.step1
            os.environ['step2'] = st.session_state.step2
            os.environ['step3'] = st.session_state.step3
            os.environ['step4'] = st.session_state.step4
            os.environ['syn_method'] = st.session_state.Syn_method
            os.environ['method'] = st.session_state.method
            os.environ['epoch'] = str(st.session_state.total_epoch)
            os.environ['eval_path'] = st.session_state.output_dir
            subprocess.Popen(f"python ui/pages/iteration_setting.py 2>&1 | tee outputs/rec.log", text=True, shell=True)
            # subprocess.Popen("python ui/pages/Align.py", text=True, shell=True)
            st.switch_page("pages/loading_pages_ui.py")

if st.session_state.selected_button == "data_gen":
    st.switch_page("pages/instruction_generation_ui.py")
elif st.session_state.selected_button == "data_filter":
    st.switch_page("pages/sampling_answer_ui.py")
elif st.session_state.selected_button == "train":
    st.switch_page("pages/training_ui.py")
elif st.session_state.selected_button == "eval":
    pass
