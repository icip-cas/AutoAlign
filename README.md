![logo](/assets/auto_logo.png)

<p align="center">
    <a href="#-quick-start">ğŸ”¥Quick Start</a> â€¢
    <a href="#-features">ğŸ“ªFeatures</a> â€¢
    <a href="#-reference-results">ğŸ“ˆResults</a> â€¢
    <a href="#-issues">ğŸ›Issues</a> â€¢
    <a href="#-citation">ğŸ“œCitation</a>
</p>

## ğŸ“£ About

Auto-Alignment is a package focusing on scalable and automated alignment methods. We aim to provide the academic community with a series of classic alignment baselines and ready-to-use automated alignment algorithms. This toolkit is designed to facilitate research in the field of LLM alignment.

The core functionalities of the toolkit include:

- Implementation of common model alignment algorithms (e.g., SFT, RS, RM, DPO, etc.)
- Implementation of various automatic model alignment algorithms (e.g., CAI, SPIN, RLCD, etc.)
- Efficient model sampling
- Automated model evaluation
- Post-training intervertion methods (e.g., Represenatation Engineering, Model Averaging, etc.)

*è¿™é‡Œæœ€å¥½æœ‰å¼ å›¾ï¼Œæ•´ä½“ä»‹ç»ä¸€ä¸‹è¿™ä¸ªä»“åº“æœ‰å“ªäº›åŠŸèƒ½/ç»„ç»‡æ–¹å¼*

## ğŸš€ News

* [2024.8.23] We released the first version of AutoAlign, which supports XXX and XXXX. More XXX are comming soonğŸ”¥ğŸ”¥ğŸ”¥. 

## ğŸ”¥ Quick Start

### ğŸ”¨ Environment Setup

*Default*

```
pip install .[train]
```

*Evaluation (Optional)*

```
pip install .[eval]
bash ./scripts/post_install.sh
```

*Install for Develop*

```
pip install -e .[dev]
pre-commit install
```

### ğŸ“‚ Data Preparation

Covert your data to the following format and XXXX.

We also prepared two examples to facilitate your usage. [data/dummy_sft.json](data/dummy_sft.json) is for supervised finetuning and [data/dummy_dpo.json](data/dummy_dpo.json) is for RL process.
<!-- Currently, we use the format in ```data/dummy_sft.json``` for supervised finetuning and the format in ```data/dummy_dpo.json``` for RL process. -->

### ğŸ’» Model Preparation

### ğŸ“š Basic Alignment Toolkit

* SFT

è¿™é‡Œç»™æ¯ä¸ªéƒ¨åˆ†å†™ä¸€ä¸ªç®€çŸ­çš„running exampleï¼ŒåŒ…å«æœ€åŸºæœ¬çš„æ•°æ®å’Œæ¨¡å‹ä¿¡æ¯
ç„¶åè¯´æ˜æ€ä¹ˆè·å–è¯¦ç»†çš„å¯é…ç½®å‚æ•°
DPOå’Œinferenceä¹Ÿç±»ä¼¼

``` bash
autoalign-cli sft
```

### Reward Modeling

```bash
autoalign-cli rm
```

### DPO

```bash
autoalign-cli dpo
```

### Inference

```bash
autoalign-cli infer --backend "vllm" \
            --model-name "Qwen2-0.5B-Instruct" \
            --model-path "Qwen/Qwen2-0.5B-Instruct" \
            --test-file "data/dummy_sft.json" \
            --template "chatml" \
            --source "qwen2_0_5b_instruct_dummy"
```

### Serve

```bash
autoalign-cli serve
```

### ğŸ›  Automated Alignment Toolkit

The introduction and scripts for each automated alignment algorithm are stored in the [experiments](experiments) folder. ï¼ˆè¿™ä¸ªæ–‡ä»¶å¤¹å»ºè®®æ¢ä¸ªåå­—ï¼Œå’Œautomated alignmentç›¸å…³çš„ï¼‰

Currently, we implemented the following algorithms for automated alignment

* RLCD

ä¸€å¥è¯ä»‹ç»ï¼šRLCD is XXXXX

è¿™é‡Œç»™ä¸€ä¸ªç®€å•çš„running exampleï¼Œç„¶åplease refer to [experiments/rlcd_sys](experiments/rlcd_sys) for detailed XXXX.

åœ¨æ¯ä¸ªç®—æ³•çš„æ–‡ä»¶ä¸‹ä¸‹é¢é…ç½®å®Œæ•´çš„ä½¿ç”¨readmeï¼Œå»ºè®®ç»Ÿä¸€ä¸€ä¸‹æ ¼å¼ã€‚éœ€è¦åŒ…æ‹¬ï¼ˆç®—æ³•çš„ä»‹ç»ã€æ•°æ®å‡†å¤‡ï¼Œæ€ä¹ˆä½¿ç”¨ï¼Œæ€ä¹ˆé…ç½®è¯¦ç»†å‚æ•°ç­‰ç­‰ï¼‰

### âœï¸ Model Evaluation

quick startä¸å»ºè®®å†™çš„è¿™ä¹ˆå¤æ‚ï¼Œå¯ä»¥å•ç‹¬åœ¨evaluationçš„æ–‡ä»¶å¤¹ä¸‹ä»‹ç»å…·ä½“çš„ï¼Œè¿™é‡Œåªéœ€è¦ç®€å•çš„running exampleï¼Œæ€ä¹ˆé…ç½®ï¼Œåœ¨å“ªé‡Œçœ‹ç»“æœå³å¯

#### Objective evaluation

## Documents

Documents of this toolkit is stored at ```./docs/```.

## Evaluation
### Objective evaluation

Objective evaluation involves assessing datasets with standard answers, where processed responses can be directly compared to these standard answers according to established rules and model performances are mesured with quantitative metrics. We utilize the OpenCompass platform to conduct these evaluations.

Usage:
``` bash
autoalign-cli eval --config eval.yaml
```
In `eval.yaml`, the `model_path` is the absolute path to the evaluated model or the relative path from the root directory of this repository.

After running the above command, `autoalign-cli` will call the interface in OpenCompass to conduct an objective dataset evaluation. We format the timestamp and append it to the model_name as a directory name(`{model_id} = {model_name + timestamp}`), storing the evaluation results in the `outputs/{model_id}` directory. The raw result will be stored at `outputs/{model_id}/opencompass_log/{opencompass_timestamp}`, in which `{opencompass_timestamp}` is the default name of opencompass output directory of an evaluation. We will summarize and display each evaluation in `outputs/{model_id}/ordered_res.csv` and `outputs/{model_id}/ordered_res.txt`(formed output, easy to read).

Before starting opencompass, we will check whether new file paths exist, including the config file: `configs/{model_id}.py`, result files: `outputs/{model_id}/ordered_res.csv` and  `outputs/{model_id}/ordered_res.txt`, opencompass logs: `outputs/{model_id}/opencompass_log/`. If one of them exists, you need to choose to continue evaluating or to exit. Continuing may cause overwriting.

## ğŸ“ª Features

è¿™é‡Œå¯ä»¥ç»™ä¸€ä¸ªè¡¨åˆ—å‡ºç°åœ¨Supportçš„æ¨¡å‹ã€æ•°æ®ã€benchmarkã€ç®—æ³•ç­‰ç­‰ã€‚

## ğŸ“ˆ Reference Results

## ğŸ“… TODO

## ğŸ“œ Citation

```bibtex
@software{AutoALign,
  author = {},
  title = {},
  url = {},
  version = {1.0.0},
  year = {2024}
}
```

## ğŸ¤ Contributing

If you would like to contribute to this project, please follow these guidelines:

1. Fork the repository.
2. Create a new branch.
3. Make your changes.
4. Submit a pull request.

## ğŸ’³ License

This project is licensed under the [MIT License](LICENSE).
